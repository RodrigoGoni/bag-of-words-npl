{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45903ec6",
   "metadata": {},
   "source": [
    "## Consignas\n",
    "**Cada experimento realizado debe estar acompañado de una explicación o interpretación de lo observado.**\n",
    "\n",
    "**1**. Vectorizar documentos. Tomar 5 documentos al azar y medir similaridad con el resto de los documentos.\n",
    "Estudiar los 5 documentos más similares de cada uno analizar si tiene sentido\n",
    "la similaridad según el contenido del texto y la etiqueta de clasificación.\n",
    "\n",
    "**2**. Construir un modelo de clasificación por prototipos (tipo zero-shot). Clasificar los documentos de un conjunto de test comparando cada uno con todos los de entrenamiento y asignar la clase al label del documento del conjunto de entrenamiento con mayor similaridad.\n",
    "\n",
    "**3**. Entrenar modelos de clasificación Naïve Bayes para maximizar el desempeño de clasificación\n",
    "(f1-score macro) en el conjunto de datos de test. Considerar cambiar parámteros\n",
    "de instanciación del vectorizador y los modelos y probar modelos de Naïve Bayes Multinomial\n",
    "y ComplementNB.\n",
    "\n",
    "**NO cambiar el hiperparámetro ngram_range de los vectorizadores**.\n",
    "\n",
    "**4**. Transponer la matriz documento-término. De esa manera se obtiene una matriz\n",
    "término-documento que puede ser interpretada como una colección de vectorización de palabras.\n",
    "Estudiar ahora similaridad entre palabras tomando 5 palabras y estudiando sus 5 más similares.\n",
    "\n",
    "**Elegir las palabras MANUALMENTE para evitar la aparición de términos poco interpretables**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0d790a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# 20newsgroups por ser un dataset clásico de NLP ya viene incluido y formateado\n",
    "# en sklearn\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a61c3e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos los datos (ya separados de forma predeterminada en train y test)\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0144e5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciamos un vectorizador\n",
    "# ver diferentes parámetros de instanciación en la documentación de sklearn https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "tfidfvect = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b519603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajustamos el vectorizador a los datos de entrenamiento y transformamos los documentos en matrices dispersas\n",
    "X_train = tfidfvect.fit_transform(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3af0f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformamos los documentos de test a matrices dispersas\n",
    "X_test = tfidfvect.transform(newsgroups_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b8e08fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tomamos 5 documentos de muestra M al azar del conjunto de test\n",
    "indices_test = random.sample(range(X_test.shape[0]), 5)\n",
    "M_test = [X_test[i] for i in indices_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fc18355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 44 stored elements and shape (1, 101631)>\n",
      "  Coords\tValues\n",
      "  (0, 18091)\t0.06733950787372323\n",
      "  (0, 18165)\t0.07293282550533227\n",
      "  (0, 18521)\t0.06711616797425575\n",
      "  (0, 19443)\t0.04700420413497767\n",
      "  (0, 21703)\t0.2183599561592284\n",
      "  (0, 23851)\t0.20846485130062659\n",
      "  (0, 24804)\t0.09447893595790471\n",
      "  (0, 24949)\t0.36905673837891106\n",
      "  (0, 26418)\t0.11895400908069945\n",
      "  (0, 34686)\t0.08815964302557198\n",
      "  (0, 41127)\t0.0774287745983133\n",
      "  (0, 43495)\t0.10082281101258993\n",
      "  (0, 46313)\t0.14377160968939295\n",
      "  (0, 51136)\t0.03602286334825344\n",
      "  (0, 51326)\t0.03722918345743305\n",
      "  (0, 55446)\t0.20144416267434195\n",
      "  (0, 56112)\t0.10342702051361426\n",
      "  (0, 56734)\t0.06076766172114788\n",
      "  (0, 57422)\t0.1985697464420248\n",
      "  (0, 63341)\t0.1449479497550483\n",
      "  (0, 67670)\t0.03387714069243376\n",
      "  (0, 67828)\t0.341742640117845\n",
      "  (0, 70270)\t0.11307602918890584\n",
      "  (0, 70632)\t0.06899818984370602\n",
      "  (0, 71819)\t0.12773271286456955\n",
      "  (0, 72108)\t0.2183599561592284\n",
      "  (0, 75193)\t0.1240133219275235\n",
      "  (0, 76456)\t0.4367199123184568\n",
      "  (0, 77870)\t0.1312478973862984\n",
      "  (0, 78397)\t0.08047904369543334\n",
      "  (0, 80369)\t0.0787395766474322\n",
      "  (0, 81646)\t0.20144416267434195\n",
      "  (0, 82947)\t0.11764000100425126\n",
      "  (0, 85227)\t0.12864229633394805\n",
      "  (0, 88532)\t0.0574657084801269\n",
      "  (0, 88565)\t0.06911916997709246\n",
      "  (0, 88679)\t0.072666451346569\n",
      "  (0, 88767)\t0.08606627669774808\n",
      "  (0, 89360)\t0.06296664704443256\n",
      "  (0, 89502)\t0.0794905384024432\n",
      "  (0, 89708)\t0.13815427980185976\n",
      "  (0, 95762)\t0.0789402712930853\n",
      "  (0, 96061)\t0.06647794427239541\n",
      "  (0, 97332)\t0.05546404600976585\n"
     ]
    }
   ],
   "source": [
    "#Mostrar el segundo documento de M_test\n",
    "print(M_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcbc100b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Documento M_test[0] (Etiqueta real: rec.autos)\n",
      "Etiquetas de los 5 documentos más similares en train:\n",
      "  - rec.autos - OK -\n",
      "  - rec.autos - OK -\n",
      "  - rec.autos - OK -\n",
      "  - rec.autos - OK -\n",
      "  - rec.autos - OK -\n",
      "\n",
      "Documento M_test[1] (Etiqueta real: rec.sport.hockey)\n",
      "Etiquetas de los 5 documentos más similares en train:\n",
      "  - rec.sport.hockey - OK -\n",
      "  - rec.sport.hockey - OK -\n",
      "  - rec.sport.hockey - OK -\n",
      "  - alt.atheism - NOT_OK -\n",
      "  - talk.politics.misc - NOT_OK -\n",
      "\n",
      "Documento M_test[2] (Etiqueta real: talk.politics.misc)\n",
      "Etiquetas de los 5 documentos más similares en train:\n",
      "  - talk.politics.misc - OK -\n",
      "  - talk.politics.misc - OK -\n",
      "  - talk.politics.misc - OK -\n",
      "  - talk.politics.misc - OK -\n",
      "  - talk.politics.misc - OK -\n",
      "\n",
      "Documento M_test[3] (Etiqueta real: talk.politics.misc)\n",
      "Etiquetas de los 5 documentos más similares en train:\n",
      "  - talk.politics.misc - OK -\n",
      "  - talk.politics.misc - OK -\n",
      "  - alt.atheism - NOT_OK -\n",
      "  - talk.politics.misc - OK -\n",
      "  - talk.religion.misc - NOT_OK -\n",
      "\n",
      "Documento M_test[4] (Etiqueta real: rec.autos)\n",
      "Etiquetas de los 5 documentos más similares en train:\n",
      "  - sci.electronics - NOT_OK -\n",
      "  - rec.autos - OK -\n",
      "  - rec.motorcycles - NOT_OK -\n",
      "  - rec.autos - OK -\n",
      "  - rec.motorcycles - NOT_OK -\n"
     ]
    }
   ],
   "source": [
    "for i, m in enumerate(M_test):\n",
    "    similarities = cosine_similarity(m, X_train)\n",
    "    most_similar_indices = np.argsort(similarities[0])[-5:][::-1]\n",
    "    test_label = newsgroups_test.target[indices_test[i]]\n",
    "    test_label_name = newsgroups_test.target_names[test_label]\n",
    "    print(f\"\\nDocumento M_test[{i}] (Etiqueta real: {test_label_name})\")\n",
    "    print(\"Etiquetas de los 5 documentos más similares en train:\")\n",
    "    for idx in most_similar_indices:\n",
    "        label_idx = newsgroups_train.target[idx]\n",
    "        label_name = newsgroups_train.target_names[label_idx]\n",
    "        match = \"- OK -\" if label_idx == test_label else \"- NOT_OK -\"\n",
    "        print(f\"  - {label_name} {match}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa5d0b1",
   "metadata": {},
   "source": [
    "# Análisis Cualitativo de Similaridad de Documentos (k-NN) - Segundo Muestreo\n",
    "\n",
    "Este análisis evalúa el rendimiento de la similaridad vectorial con un **nuevo conjunto de 5 documentos de prueba**. Se utiliza el método de los 5 Vecinos Más Similares ($K=5$).\n",
    "\n",
    "| Documento | Etiqueta Real | Vecinos OK/Total | Coincidencia (%) | Tipo de Error y Análisis |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| **M_test[0]** | `soc.religion.christian` | 2/5 | 40% | **Solapamiento Religioso/Político.** El texto probablemente debate temas religiosos que tocan política (armas, Mideast) o ética general (`talk.religion.misc`). **Similaridad comprensible** pero fallo de clase. |\n",
    "| **M_test[1]** | `comp.sys.ibm.pc.hardware` | **3/5** | **60%** | **Rendimiento Aceptable.** Los fallos están en temas relacionados (`misc.forsale` por venta de componentes, `comp.os.ms-windows.misc` por discusión de software/drivers). La similaridad es **temáticamente cercana**. |\n",
    "| **M_test[2]** | `misc.forsale` | **0/5** | **0%** | **Fallo Severo (0%).** El contenido de venta es similar a temas muy dispares (Política, Hardware, Deportes, Cripto). Esto sugiere que el texto de venta es **extremadamente corto** o **usa un vocabulario genérico** que se asemeja al debate o a listados técnicos. |\n",
    "| **M_test[3]** | `comp.os.ms-windows.misc` | **0/5** | **0%** | **Fallo Temático Alto.** El documento sobre Windows es abrumadoramente similar a documentos de venta (`misc.forsale`) y gráficos (`comp.graphics`). La similaridad es probablemente causada por el uso de términos comerciales (\"busco\", \"vendo\", \"licencia\", \"ofrezco\") o discutiendo *software* de gráficos, lo que **desvía el vector** de la clase `windows.misc` pura. |\n",
    "| **M_test[4]** | `sci.med` | **0/5** | **0%** | **Fallo de Contexto (Debate).** El contenido médico se asemeja a documentos de religión/política/ateísmo. El texto casi con seguridad aborda un **tema médico controvertido** (ej. ética, aborto, vacunas) donde el vocabulario de la discusión pesa más que el vocabulario puramente científico. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a5766a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score Macro para clasificación por prototipos: 0.5050\n"
     ]
    }
   ],
   "source": [
    "# Clasificación por prototipos (zero-shot KNN): asignar etiqueta del documento de train más similar a cada test\n",
    "\n",
    "predictions = []\n",
    "for test_doc in X_test:\n",
    "    similarities = cosine_similarity(test_doc, X_train)[0]\n",
    "    most_similar_idx = np.argmax(similarities)\n",
    "    predicted_label = newsgroups_train.target[most_similar_idx]\n",
    "    predictions.append(predicted_label)\n",
    "\n",
    "# Calcular métricas\n",
    "f1_macro = f1_score(newsgroups_test.target, predictions, average='macro')\n",
    "print(f\"F1-Score Macro para clasificación por prototipos: {f1_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dbadcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor F1-Macro para MultinomialNB: 0.6726 con params: {'model__alpha': 0.1, 'vectorizer__max_df': 0.5, 'vectorizer__min_df': 1, 'vectorizer__stop_words': 'english'}\n",
      "Mejor F1-Macro para ComplementNB: 0.6978 con params: {'model__alpha': 0.5, 'vectorizer__max_df': 0.5, 'vectorizer__min_df': 1, 'vectorizer__stop_words': 'english'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6978053768076979"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir parámetros para el pipeline (vectorizador + modelo)\n",
    "pipeline_params = {\n",
    "    'vectorizer__min_df': [1, 5, 10],\n",
    "    'vectorizer__max_df': [0.5, 0.8, 1.0],\n",
    "    'vectorizer__stop_words': [None, 'english'],\n",
    "    'model__alpha': [0.1, 0.5, 1.0, 2.0]\n",
    "}\n",
    "\n",
    "# Función para entrenar y evaluar con pipeline\n",
    "def train_and_evaluate(model_class):\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', TfidfVectorizer()),\n",
    "        ('model', model_class())\n",
    "    ])\n",
    "    grid = GridSearchCV(pipeline, pipeline_params, cv=3, scoring='f1_macro')\n",
    "    grid.fit(newsgroups_train.data, newsgroups_train.target)\n",
    "    predictions = grid.predict(newsgroups_test.data)\n",
    "    f1 = f1_score(newsgroups_test.target, predictions, average='macro')\n",
    "    print(f\"Mejor F1-Macro para {model_class.__name__}: {f1:.4f} con params: {grid.best_params_}\")\n",
    "    return f1\n",
    "\n",
    "# Probar MultinomialNB\n",
    "train_and_evaluate(MultinomialNB)\n",
    "\n",
    "# Probar ComplementNB\n",
    "train_and_evaluate(ComplementNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a7fea65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Palabra: god\n",
      "5 palabras más similares:\n",
      "  - jesus\n",
      "  - bible\n",
      "  - that\n",
      "  - existence\n",
      "  - christ\n",
      "\n",
      "Palabra: computer\n",
      "5 palabras más similares:\n",
      "  - decwriter\n",
      "  - deluged\n",
      "  - harkens\n",
      "  - shopper\n",
      "  - the\n",
      "\n",
      "Palabra: windows\n",
      "5 palabras más similares:\n",
      "  - dos\n",
      "  - ms\n",
      "  - microsoft\n",
      "  - nt\n",
      "  - for\n",
      "\n",
      "Palabra: medicine\n",
      "5 palabras más similares:\n",
      "  - strengthens\n",
      "  - dislikes\n",
      "  - nearer\n",
      "  - foremost\n",
      "  - surpress\n",
      "\n",
      "Palabra: politics\n",
      "5 palabras más similares:\n",
      "  - iftccu\n",
      "  - hesh\n",
      "  - fascism\n",
      "  - bmwmoa\n",
      "  - lapse\n"
     ]
    }
   ],
   "source": [
    "# Transponer la matriz documento-término a término-documento\n",
    "X_train_T = X_train.T  # Ahora filas son términos, columnas documentos\n",
    "\n",
    "# Obtener el vocabulario\n",
    "vocab = tfidfvect.get_feature_names_out()\n",
    "\n",
    "# Elegir 5 palabras manualmente\n",
    "words = [\"god\", \"computer\", \"windows\", \"medicine\", \"politics\"]\n",
    "word_indices = [np.where(vocab == word)[0][0] for word in words if word in vocab]\n",
    "\n",
    "for idx in word_indices:\n",
    "    word = vocab[idx]\n",
    "    similarities = cosine_similarity(X_train_T[idx:idx+1], X_train_T)[0]\n",
    "    most_similar_indices = np.argsort(similarities)[-6:][::-1][1:]  # Excluir la palabra misma\n",
    "    print(f\"\\nPalabra: {word}\")\n",
    "    print(\"5 palabras más similares:\")\n",
    "    for sim_idx in most_similar_indices:\n",
    "        sim_word = vocab[sim_idx]\n",
    "        print(f\"  - {sim_word}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
